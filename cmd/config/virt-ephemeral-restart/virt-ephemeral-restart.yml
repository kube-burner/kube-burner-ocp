{{- $testNamespacesLabelKey := "kube-burner.io/test-name" -}}
{{- $testNamespacesLabelValue := "virt-ephemeral-restart" -}}
{{- $baseDataVolumeName := "master-image" -}}
{{- $baseVolumeSnapshotName := "master-image" -}}
{{- $baseDataSourceName := "master-image" -}}
{{- $createVMsJobName := "create-vms" -}}
{{- $vmName := "ephemeral-vm" -}}
{{- $sshPublicKeySecretName := "burner-clone-virt-ephemeral-restart" -}}

global:
  measurements:
  - name: vmiLatency
  - name: dataVolumeLatency

metricsEndpoints:
{{ if .ES_SERVER }}
  - metrics: [{{.METRICS}}]
    alerts: [{{.ALERTS}}]
    indexer:
      esServers: ["{{.ES_SERVER}}"]
      insecureSkipVerify: true
      defaultIndex: {{.ES_INDEX}}
      type: opensearch
{{ end }}
{{ if .LOCAL_INDEXING }}
  - metrics: [{{.METRICS}}]
    alerts: [{{.ALERTS}}]
    indexer:
      type: local
      metricsDirectory: ./virt-ephemeral-restart-results
{{ end }}

jobs:
- name: start-fresh
  jobType: delete
  waitForDeletion: true
  qps: 5
  burst: 10
  objects:
  - kind: Namespace
    labelSelector:
      {{ $testNamespacesLabelKey }}: {{ $testNamespacesLabelValue }}

# Create the DV in a separate job to make sure it is ready before continuing
- name: create-base-image-dv
  jobType: create
  jobIterations: 1
  qps: 20
  burst: 20
  namespacedIterations: false
  namespace: {{ .testNamespace }}
  namespaceLabels:
    {{ $testNamespacesLabelKey }}: {{ $testNamespacesLabelValue }}
  # verify object count after running each job
  verifyObjects: true
  errorOnVerify: true
  # wait all VMI be in the Ready Condition
  waitWhenFinished: false
  podWait: true
  # timeout time after waiting for all object creation
  maxWaitTimeout: 30m
  # wait before job completes to allow metrics collection
  jobPause: 10s
  # Do not clean the namespaces
  cleanup: false
  # Set missing key as empty to allow using default values
  defaultMissingKeysWithZero: true
  objects:
  - objectTemplate: templates/baseImageDataVolume.yml
    replicas: 1
    inputVars:
      baseDataVolumeName: {{ $baseDataVolumeName }}
      baseDataVolumeUrl: "docker://quay.io/containerdisks/fedora:41"
      storageClassName: {{ .storageClassName }}
      baseDataVolumeSize: "6Gi"
      accessMode: {{ .accessMode }}

- name: create-data-source
  jobType: create
  jobIterations: 1
  qps: 20
  burst: 20
  namespacedIterations: false
  namespace: {{ .testNamespace }}
  namespaceLabels:
    {{ $testNamespacesLabelKey }}: {{ $testNamespacesLabelValue }}
  # verify object count after running each job
  verifyObjects: true
  errorOnVerify: true
  # wait all VMI be in the Ready Condition
  waitWhenFinished: false
  podWait: true
  # timeout time after waiting for all object creation
  maxWaitTimeout: 30m
  # wait before job completes to allow metrics collection
  jobPause: 10s
  # Do not clean the namespaces
  cleanup: false
  # Set missing key as empty to allow using default values
  defaultMissingKeysWithZero: true
  objects:
  {{ if .volumeSnapshotClassName | default false }}
  - objectTemplate: templates/baseImageDataVolumeSnapshot.yml
    replicas: 1
    inputVars:
      baseVolumeSnapshotName: {{ $baseVolumeSnapshotName }}
      volumeSnapshotClassName: {{ .volumeSnapshotClassName }}
      baseVolumeSnapshotPVCName: {{ $baseDataVolumeName }}
  {{ end }}
  - objectTemplate: templates/baseImageDataSource.yml
    replicas: 1
    inputVars:
      baseDataSourceName: {{ $baseDataSourceName }}
      baseDataSourcePVCName: {{ $baseDataVolumeName }}
      baseDataSourcePVCNamespace: {{ .testNamespace }}
      baseDataSourceSnapshotName: {{ $baseVolumeSnapshotName }}
      baseDataSourceSnapshotNamespace: {{ .testNamespace }}
      useSnapshot: {{ .volumeSnapshotClassName | default false }}
    waitOptions:
      customStatusPaths:
      - key: '(.conditions.[] | select(.type == "Ready")).status'
        value: "True"

- name: {{ $createVMsJobName }}
  jobType: create
  jobIterations: {{ .vmGroups | len }}
  qps: 20
  burst: 20
  namespacedIterations: false
  namespace: {{ .testNamespace }}
  # verify object count after running each job
  verifyObjects: true
  errorOnVerify: true
  # wait all VMI be in the Ready Condition
  waitWhenFinished: false
  podWait: true
  # timeout time after waiting for all object creation
  maxWaitTimeout: 1h
  jobPause: 10s
  # cleanup cleans previous execution (not deleted or failed)
  cleanup: false
  # Set missing key as empty to allow using default values
  defaultMissingKeysWithZero: true
  beforeCleanup: "./check.sh check_vm_running kube-burner.io/job {{ $createVMsJobName }} {{ .testNamespace }} {{ .privateKey }} fedora"
  objects:

  - objectTemplate: templates/secret_ssh_public.yml
    runOnce: true
    replicas: 1
    inputVars:
      name: {{ $sshPublicKeySecretName }}
      publicKeyPath: {{ .publicKey }}

  - objectTemplate: templates/vm.yml
    replicas: {{ .vmsPerIteration }}
    inputVars:
      vmName: {{ $vmName }}
      rootdiskVolumeSourceRef:
        kind: DataSource
        name: {{ $baseDataSourceName }}
        namespace: {{ .testNamespace }}
      storageClassName: {{ .storageClassName }}
      sshPublicKeySecret: {{ $sshPublicKeySecretName }}
      accessMode: {{ .accessMode }}

- name: stop-ephemeral-vms
  jobType: kubevirt
  qps: 20
  burst: 20
  jobIterations: 1
  maxWaitTimeout: 1h
  objectWait: true
  objects:
  - kubeVirtOp: stop
    labelSelector:
      kube-burner.io/job: {{ $createVMsJobName }}

- name: start-vms
  jobType: read
  metricsAggregate: true
  qps: 20
  burst: 20
  jobIterations: 1
  maxWaitTimeout: 1h
  waitWhenFinished: false
  objects:
  - apiVersion: kubevirt.io/v1
    kind: VirtualMachine
    labelSelector:
      kube-burner.io/job: {{ $createVMsJobName }}

{{ range $vmGroupIndex := .vmGroups }}
- name: "delete-ephemeral-volumes-{{ $vmGroupIndex }}"
  jobType: delete
  waitWhenFinished: false
  waitForDeletion: false
  metricsAggregate: true
  qps: 20
  burst: 20
  objects:
  - apiVersion: cdi.kubevirt.io/v1beta1
    kind: DataVolume
    labelSelector:
      virt-ephemeral-restart.kube-burner.io/group: "group-{{ $vmGroupIndex }}"

- name: "start-ephemeral-vms-{{ $vmGroupIndex }}"
  jobType: kubevirt
  waitWhenFinished: false
  metricsAggregate: true
  qps: 20
  burst: 20
  jobIterations: 1
  jobPause: 1m
  objects:
  - kubeVirtOp: start
    labelSelector:
      virt-ephemeral-restart.kube-burner.io/group: "group-{{ $vmGroupIndex }}"
{{ end }}

- name: wait-running
  jobType: read
  qps: 20
  burst: 20
  jobIterations: 1
  maxWaitTimeout: 1h
  waitWhenFinished: true
  jobPause: 1m
  beforeCleanup: "./check.sh check_vm_running kube-burner.io/job {{ $createVMsJobName }} {{ .testNamespace }} {{ .privateKey }} fedora"
  objects:
  - apiVersion: kubevirt.io/v1
    kind: VirtualMachine
    labelSelector:
      kube-burner.io/job: {{ $createVMsJobName }}
